{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "def getData(symbol):\n",
    "    # conn = pyodbc.connect(\"DRIVER={SQL Server};SERVER=lenovo-desktop;DATABASE=Qihuo;UID=samtsql;PWD=F(W}q:TsyK,7^+>`P28e79s#Uc5n\")\n",
    "    conn = pyodbc.connect(\"DRIVER={SQL Server};SERVER=.;Database=Qihuo;Trusted_Connection=True\")    \n",
    "    query = f\"\"\"select m1.date as 'Date',DATEPART(hour, m1.Date) AS 'Hour',DATEPART(Month, m1.Date) AS 'Month',\n",
    "     m1.[close]/m1.[LastClose] - 1 as 'StockReturn',\n",
    "     m1.[Close] as 'Stock'\n",
    "     from MinuteQuoteLag m1\n",
    "    where m1.Symbol = '{symbol}'\n",
    "    order by m1.date\"\"\"\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', UserWarning)\n",
    "        df = pd.read_sql(query, conn)\n",
    "        df.set_index('Date', inplace=True)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData(df):\n",
    "    df[f\"OutPerform\"] = df['StockReturn'] \n",
    "    df[\"Target\"] = (df.apply(lambda x: x > 0)[\"OutPerform\"]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictors(df):\n",
    "    predictors = ['Hour','Month']\n",
    "    for i in range(14):\n",
    "        # df[f'OutPerform{pow(2,i)*5}'] = df['OutPerform'].rolling(pow(2,i)).sum()\n",
    "        # predictors.append(f'OutPerform{pow(2,i)*5}')\n",
    "        df[f'StockReturn{pow(2,i)*5}'] = df['StockReturn'].rolling(pow(2,i)).sum()\n",
    "        predictors.append(f'StockReturn{pow(2,i)*5}')\n",
    "\n",
    "    return predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMLdata(df, predictors):\n",
    "    # df['OutPerform'] = df['OutPerform'].rolling(6).sum()\n",
    "    # df = df[df.index.minute % 30 == 0]\n",
    "    prev = df.copy()\n",
    "    prev = prev.shift(1)\n",
    "    data = df[[\"OutPerform\",\"Target\",\"Stock\", \"StockReturn\"]]\n",
    "    data = data.join(prev[predictors])\n",
    "\n",
    "    data = data.copy().dropna()\n",
    "    # print(data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train, test, predictors, model):\n",
    "    model.fit(train[predictors], train[\"Target\"])\n",
    "    preds = model.predict_proba(test[predictors])[:,1]\n",
    "    preds = pd.Series(preds, index=test.index, name=\"Predictions\")\n",
    "    combined = pd.concat([test[\"Target\"], preds], axis=1)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data, model, predictors, start=20000, step=5000):\n",
    "    all_predictions = []\n",
    "    loop = 0\n",
    "    for i in range(start, data.shape[0], step):\n",
    "        train = data.iloc[loop * step:i].copy()\n",
    "        test = data.iloc[i:(i+step)].copy()\n",
    "        predictions = predict(train, test, predictors, model)\n",
    "        all_predictions.append(predictions)\n",
    "        loop = loop + 1\n",
    "\n",
    "    # print(all_predictions)    \n",
    "    return pd.concat(all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, min_samples_split=1200, random_state=1)\n",
    "symbols = [\n",
    "'j',\n",
    "'rm',\n",
    "'ru',\n",
    "'p',\n",
    "'cf',\n",
    "'sr',\n",
    "'c',\n",
    "'l',\n",
    "'al',\n",
    "'au',\n",
    "'rb',\n",
    "'ta',\n",
    "'oi',\n",
    "'fg',\n",
    "'jd',\n",
    "'m',\n",
    "'pp',\n",
    "'ag',\n",
    "'jm',\n",
    "'i',\n",
    "'zn',\n",
    "'a',\n",
    "'fu',\n",
    "'bu',\n",
    "'y',\n",
    "'hc',\n",
    "'vv'\n",
    "]\n",
    "for s in symbols:\n",
    "    df = getData(s)\n",
    "    transformData(df)\n",
    "    predictors = getPredictors(df)\n",
    "    data = getMLdata(df, predictors)\n",
    "    predictions = backtest(data, model, predictors)\n",
    "    pickle.dump(model, open(f\"ModelCommodity/{s}\", 'wb'))\n",
    "    tempData = data[['OutPerform']].copy()\n",
    "    result = pd.merge(tempData, predictions, left_index=True, right_index=True)\n",
    "    result.to_csv(f'./ResultCommodity/{s}.csv')\n",
    "\n",
    "    # precision_score(predictions[\"Target\"], predictions[\"Predictions\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gain  count       avg\n",
      "year                           \n",
      "2012 -0.284726    875 -0.000325\n",
      "2013 -0.982732   3179 -0.000309\n",
      "2014 -1.977320   5737 -0.000345\n",
      "2015 -3.560148   8145 -0.000437\n",
      "2016 -0.814367   3497 -0.000233\n",
      "2017 -0.120399    398 -0.000303\n",
      "2018 -0.450189   1521 -0.000296\n",
      "2019 -1.101711   3811 -0.000289\n",
      "2020 -0.741201   1983 -0.000374\n",
      "2021 -0.007002     77 -0.000091\n",
      "29223\n",
      "-0.0003435579759670132\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files = [f for f in glob.glob(\"ResultCommodity/*.csv\")]\n",
    "result = pd.DataFrame(columns = ['symbol', 'year', 'gain','count'])\n",
    "for file in files:\n",
    "\n",
    "    s = file.split('\\\\')[1].replace('.csv','')\n",
    "    df = pd.read_csv(f'ResultCommodity/{s}.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df['year'] = df.index.strftime('%Y')\n",
    "    groupbyyear = df.groupby('year')\n",
    "\n",
    "    for group_name, df_group in groupbyyear:\n",
    "        count = 0\n",
    "        newtrade = True\n",
    "        gsum = 0\n",
    "        for ind in df_group.index:\n",
    "            if df_group['Predictions'][ind] < .25:\n",
    "                gsum = gsum + df_group['OutPerform'][ind]\n",
    "                if newtrade == True:\n",
    "                    count = count + 1\n",
    "                    newtrade = False\n",
    "            elif df_group['Predictions'][ind] <= .35 and newtrade == False:\n",
    "                gsum = gsum + df_group['OutPerform'][ind]\n",
    "            else:\n",
    "                newtrade = True \n",
    "\n",
    "        if count > 0:       \n",
    "            result.loc[len(result.index)] = [s, group_name, gsum, count]\n",
    "\n",
    "dfgain = result.groupby('year')['gain'].sum()\n",
    "dfcount = result.groupby('year')['count'].sum()\n",
    "dfresult = dfgain.to_frame().merge(dfcount.to_frame(), left_index=True, right_index=True)\n",
    "dfresult['avg'] = dfresult['gain']/dfresult['count']\n",
    "print(dfresult)\n",
    "print(dfresult['count'].sum())\n",
    "print(dfresult['gain'].sum()/dfresult['count'].sum())            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            gain  count       avg\n",
      "symbol                           \n",
      "a      -0.042197     30 -0.001407\n",
      "ag     -0.335002   2025 -0.000165\n",
      "al     -0.785593   3921 -0.000200\n",
      "au      0.017663    670  0.000026\n",
      "bu     -0.141579    324 -0.000437\n",
      "c      -1.585053   6137 -0.000258\n",
      "cf      0.007078     73  0.000097\n",
      "fg     -1.723660   3884 -0.000444\n",
      "fu     -0.020271     78 -0.000260\n",
      "hc     -0.032414    288 -0.000113\n",
      "i      -0.582729    901 -0.000647\n",
      "j      -1.654241   3515 -0.000471\n",
      "jm     -0.557771   1614 -0.000346\n",
      "l      -0.028069     18 -0.001559\n",
      "m      -0.017130      3 -0.005710\n",
      "oi     -0.020486     27 -0.000759\n",
      "p      -0.022030    134 -0.000164\n",
      "rb     -0.127814    395 -0.000324\n",
      "rm      0.026978     23  0.001173\n",
      "ru     -0.035411     12 -0.002951\n",
      "sr      0.008242     18  0.000458\n",
      "ta     -0.046809     28 -0.001672\n",
      "vv     -2.254723   4647 -0.000485\n",
      "y      -0.041238     29 -0.001422\n",
      "zn     -0.045533    429 -0.000106\n",
      "29223\n",
      "-0.00034355797596701324\n"
     ]
    }
   ],
   "source": [
    "dfgain = result.groupby('symbol')['gain'].sum()\n",
    "dfcount = result.groupby('symbol')['count'].sum()\n",
    "dfresult = dfgain.to_frame().merge(dfcount.to_frame(), left_index=True, right_index=True)\n",
    "dfresult['avg'] = dfresult['gain']/dfresult['count']\n",
    "print(dfresult)\n",
    "print(dfresult['count'].sum())\n",
    "print(dfresult['gain'].sum()/dfresult['count'].sum())  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4223721b935e787d1a81dca878f9f2d2b750048c9eff3ca6a507cac59c6a2e97"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('stock_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
